{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workflow\n",
    "https://docs.google.com/document/d/1kIbxaqzdPZqHEJRxwuFCAar-G8W78VFRgDUEF5Mesjw/edit?invite=CI_q4swC&tab=t.0\n",
    "\n",
    "\n",
    "# To-Do\n",
    "- Check Ressources OC à utiliser au début : https://openclassrooms.com/fr/paths/795/projects/1517/resources\n",
    "\n",
    "- Ressources to watch\n",
    "    - https://www.youtube.com/playlist?list=PLFELoXeMDOJOaI2W9By0Y30ZhLSf6Q4Si (Seconde vidéo encore)\n",
    "    - https://cs231n.github.io/  (CNN for Visual Recognition)\n",
    "\n",
    "\n",
    "- Analyse pré-exploratoire et préparation des données\n",
    "    - Données train et val\n",
    "    - mapping des classes en catégories > https://github.com/mcordts/cityscapesScripts/blob/master/cityscapesscripts/helpers/labels.py\n",
    "    - Regarder l'équilibre des catégories avant le train-test-split\n",
    "\n",
    "- Prétraitement des données\n",
    "    - Redimenssionnement des img8bit avec interpolation ? BILINEAR ? Autre preprocessing ?\n",
    "    - Redimenssionnement des images de masques avec interpolation NEAREST (couleur + niveaux de gris)\n",
    "    - Normalisation des images\n",
    "\n",
    "- Implémenter le data generator\n",
    "    - Créer un DataLoader\n",
    "    - Créer un DataLoader avec Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Présentation des données "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**====================  Dossier `Raw`  ====================**\n",
    "\n",
    "\n",
    "Le jeu de données utilisé pour la conception du modèle de segmentation d'images est composé de deux répertoires:\n",
    "- Un répertoire `gtFine` contenant les images de masques annotées (20 000 fichiers). Chaque image se distingue par 4 fichiers différents:\n",
    "    - Un fichier `color` en couleurs (5 000 fichiers png)\n",
    "    - Un fichier `instanceIds` en niveaux de gris (5 000 fichiers png)\n",
    "    - Un fichier `labelIds` en niveaux de gris (5 000 fichiers png)\n",
    "    - Un fichier `polygons` contenant les coordonnées des zones segmentéees (5 000 fichiers json)\n",
    "- Un répertoire `leftImg8bit` contenant les images brutes en couleurs (5 000 fichiers)\n",
    "\n",
    "\n",
    "Chacun de ces répertoires est ensuite subdivisé en trois sous répertoires, qui eux mêmes contiennent des sous-répertoires en fonction des villes:\n",
    "- `train` contenant les données d'entraînement (2975 images)\n",
    "- `val` contenant les données de validation  (500 images)\n",
    "- `test` dont les annotations ne sont pas rendues publiques, donc inexploitables dans le cas présent (1525 images)\n",
    "\n",
    "\n",
    "Pour plus d'informations sur le dataset, merci de lire le README suivant : https://github.com/mcordts/cityscapesScripts/blob/master/README.md\n",
    "\n",
    "**====================  Dossier `Sorted`  ====================**\n",
    "\n",
    "\n",
    "La première étape consiste à préparer les dossiers pour le jeu d'entraînement, de validation et de test dans ce nouveau dossier.<br>\n",
    "Premièrement, on ignore les dossiers de test puisque nous n'avons pas accès aux annotations.<br>\n",
    "\n",
    "\n",
    "Après ces étapes de préparation, le dossier `Sorted` contiendra les données suivantes:\n",
    "- Un répertoire `train` contenant uniquement les fichiers d'images et de masques d'entraînement en niveaux de gris `labelIds` et en couleur `color` soit un total de 2975 * 3 = 8925 fichiers\n",
    "- Un répertoire `test` contenant uniquement les fichiers d'images et de masques de validation du dossier `val` en niveaux de gris `labelIds` et en couleur `color` soit un total de 500 * 3 = 1500 fichiers\n",
    "\n",
    "\n",
    "Commençons par vérifier que nous avons bien toutes les données après avoir exécutées les commandes bash dans le terminal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train files:  8925\n",
      "Test files:  1500\n"
     ]
    }
   ],
   "source": [
    "# Path to the root directory\n",
    "root_dir = Path.cwd().parent\n",
    "# Path to the train directory\n",
    "train_dir = root_dir / \"data\" / \"Sorted\" / \"train\"\n",
    "# Path to the test directory\n",
    "test_dir = root_dir / \"data\" / \"Sorted\" / \"test\"\n",
    "# Print the number of files after sorting the files\n",
    "print(\"Train files: \", len(os.listdir(train_dir)))\n",
    "print(\"Test files: \", len(os.listdir(test_dir)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
