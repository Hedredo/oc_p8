# Notes session de mentorat du 17 janvier 2025

## Objectifs de la session précédente
- Tester plusieurs modèles:
    - UNET avec ou sans augment
    - Réaliser l'analyse des classes pour l'équilibrage
    - UNET avec une fonction de perte différente (DICE, FOCAL, etc)
    - Utiliser deux fonctions de perte + sum
- Relire le workflow de l'étape 4
- Ajouter des transformations dans le data generator
- Check les ressources avec entraînement GPU

## Objectifs pour la prochaine session


## Questions à poser
- Quel optimizer conseillé (AdamW, Adam, SGD) ?

## Notes
1. Le changement de la fonction de perte 